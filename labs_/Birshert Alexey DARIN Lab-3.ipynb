{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_kg_hide-input": true,
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skimage import data\n",
    "from skimage.transform import resize\n",
    "\n",
    "import torch\n",
    "from torch import utils\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import math\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "dec2c7e0f5865614e38e122b631246b69bb151f0"
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "test_batch_size = 512\n",
    "\n",
    "image_size = 40\n",
    "\n",
    "learning_rate = 0.003\n",
    "\n",
    "epoches_num = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9545b7b968f67fb1a06d96a1b8312e8a61b02704"
   },
   "outputs": [],
   "source": [
    "def dataset_(path, id_dict):\n",
    "    print(\"\\nStarted dataset \", path, \"\\n\", sep = '')\n",
    "    \n",
    "    data = np.load(path)\n",
    "    \n",
    "    # resize\n",
    "    for i in range(len(data)):\n",
    "        data[i][0] = resize(data[i][0], (image_size, image_size))\n",
    "        \n",
    "    # dealing with labels   \n",
    "    for i in range(len(data)):\n",
    "        data[i][1] = id_dict[data[i][1]]\n",
    "        \n",
    "    # dataset      \n",
    "    x = [data[i][0] for i in range(len(data))]\n",
    "    data_x = torch.stack([torch.from_numpy(i).type(torch.FloatTensor) for i in x])\n",
    "\n",
    "    y = [data[i][1] for i in range(len(data))]\n",
    "    data_y = torch.stack([torch.tensor(i) for i in y])\n",
    "        \n",
    "    dataset_data = utils.data.TensorDataset(data_x,data_y)\n",
    "    \n",
    "    # free some space\n",
    "    del x\n",
    "    del y\n",
    "    del data\n",
    "    del data_x\n",
    "    del data_y\n",
    "    \n",
    "    print(\"\\nFinished dataset \", path, \"\\n\", sep = '')\n",
    "    \n",
    "    return dataset_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3d4117bf6ea9463ca9ac194e503acecd3f9329e8"
   },
   "outputs": [],
   "source": [
    "data_id = np.load(\"../input/train-1.npy\")\n",
    "\n",
    "id_dict = {}\n",
    "\n",
    "id_curr = 0\n",
    "for i in range(len(data_id)):\n",
    "    if (not(data_id[i][1] in id_dict)):\n",
    "        id_dict[data_id[i][1]] = id_curr\n",
    "        id_curr += 1\n",
    "        \n",
    "del data_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f5dc056e0fe2df3980c6e3f93e8d319bc73fccd1"
   },
   "outputs": [],
   "source": [
    "data1 = dataset_(\"../input/train-1.npy\", id_dict)\n",
    "data2 = dataset_(\"../input/train-2.npy\", id_dict)\n",
    "data3 = dataset_(\"../input/train-3.npy\", id_dict)\n",
    "data4 = dataset_(\"../input/train-4.npy\", id_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e2fb0f561c56a7e48e904aa8b017804c389ccf3a"
   },
   "outputs": [],
   "source": [
    "whole_data = torch.utils.data.ConcatDataset((data1, data2, data3, data4))\n",
    "\n",
    "print(len(whole_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "17df7d5f38e707f83c39c1e153cec4908344c4ce"
   },
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = torch.utils.data.random_split(whole_data, (330000, 2987))\n",
    "\n",
    "print(len(train_dataset))\n",
    "print(len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "12958451342c912764ae8b443adcc6c797bd367c"
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size, shuffle = True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, test_batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "04c9336490d9361067983309904177369089aa65"
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):    \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "          \n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "          \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(p = 0.5),\n",
    "            nn.Linear(image_size * image_size * 4, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p = 0.4),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p = 0.4),\n",
    "            nn.Linear(512, 1000)\n",
    "        )\n",
    "          \n",
    "        for m in self.features.children():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "        \n",
    "        for m in self.classifier.children():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "            elif isinstance(m, nn.BatchNorm1d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "                \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.shape[0], 1, x.shape[1], x.shape[2])\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        \n",
    "        return x  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "04240de23965033f21411bafad4d6649e856ce8b"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(1200)\n",
    "\n",
    "model = Net()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.7)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "    criterion = criterion.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3335508bb8bd5a87e8d4507d396405950ff21b6c",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    exp_lr_scheduler.step()\n",
    "    \n",
    "    batches = len(train_loader)\n",
    "    percent = {int(batches * 1 / 5) : 20,\n",
    "               int(batches * 2 / 5) : 40, \n",
    "               int(batches * 3 / 5) : 60, \n",
    "               int(batches * 4 / 5) : 80,\n",
    "               batches - 1 : 100}\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        if (batch_idx in percent):\n",
    "            print(\"{}% ready\".format(percent[batch_idx]))\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            data = data.cuda()\n",
    "            target = target.cuda()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(\"Training finished\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4e239373c772b529bc432c7ef9ff730d3bd6a85a"
   },
   "outputs": [],
   "source": [
    "def test_model(data_loader, title):\n",
    "    print(\"Testing\", title)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "    \n",
    "        for data, target in data_loader:\n",
    "            if torch.cuda.is_available():\n",
    "                data = data.cuda()\n",
    "                target = target.cuda()\n",
    "        \n",
    "            output = model(data)\n",
    "            \n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "    \n",
    "    print('Accuracy: {}/{} ({:.3f}%)\\n'.format(correct, len(data_loader.dataset),\n",
    "        100. * correct / len(data_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8cec4778fac872ec1088a9e0ccab547d248376fd",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for epoch in range(epoches_num):\n",
    "    print(\"Epoch number\", epoch + 1)\n",
    "    train(epoch)\n",
    "    test_model(train_loader, \"train set\")\n",
    "    test_model(test_loader, \"test set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "21d59db7a707c72b2587d78b9183b04be165a85a"
   },
   "outputs": [],
   "source": [
    "def prediciton(data_loader):\n",
    "    model.eval()\n",
    "    test_pred = torch.LongTensor()\n",
    "    \n",
    "    for data, target in data_loader:\n",
    "        if torch.cuda.is_available():\n",
    "            data = data.cuda()\n",
    "            \n",
    "        output = model(data)\n",
    "        \n",
    "        pred = output.cpu().data.max(1, keepdim=True)[1]\n",
    "        test_pred = torch.cat((test_pred, pred), dim=0)\n",
    "        \n",
    "    return test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1c8746446c8094a83530b4a24edc6e58211680d9"
   },
   "outputs": [],
   "source": [
    "test = np.load(\"../input/test.npy\")\n",
    "\n",
    "for i in range(len(test)):\n",
    "        test[i] = resize(test[i], (image_size, image_size))\n",
    "        \n",
    "x = [test[i] for i in range(len(test))]\n",
    "data_x = torch.stack([torch.from_numpy(i).type(torch.FloatTensor) for i in x])\n",
    "\n",
    "y = [0 for i in range(len(test))]\n",
    "data_y = torch.stack([torch.tensor(i) for i in y])\n",
    "\n",
    "dataset_test = utils.data.TensorDataset(data_x,data_y)\n",
    "\n",
    "final_test_loader = torch.utils.data.DataLoader(dataset_test, test_batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c343f0565f27cf34d5add975ffd0bf3f25e36461"
   },
   "outputs": [],
   "source": [
    "test_pred = prediciton(final_test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e35770c14368f5d9196e5c77dafcd2c1b09c8b9e"
   },
   "outputs": [],
   "source": [
    "reverse = {}\n",
    "\n",
    "for key in id_dict:\n",
    "    reverse[id_dict[key]] = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e1fc1a9e3d12736d10c4d4b8ab5c7bdb45f33887"
   },
   "outputs": [],
   "source": [
    "for i in range(len(test_pred)):\n",
    "    test_pred[i] = reverse[test_pred[i].item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b4b02bddea1004c142991ed0a021a5b2123a2ccb"
   },
   "outputs": [],
   "source": [
    "out_df = pd.DataFrame(np.c_[np.arange(1, len(test_pred)+1)[:,None], test_pred.numpy()], \n",
    "                      columns=['Id', 'Category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "67af3620ddcb64eabd4231202efbc761ef1176e9"
   },
   "outputs": [],
   "source": [
    "out_df.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
